# Run utils

    >>> from gage._internal.types import *
    >>> from gage._internal.run_util import *

## Make run

`make_run()` creates a new run in a runs root directory.

    >>> runs_root = make_temp_dir()
    >>> opref = OpRef("test", "test")
    >>> run = make_run(opref, runs_root)

    >>> ls(runs_root, include_dirs=True)  # +parse
    {x:run_id}.meta
    {y:run_id}.meta/opref

    >>> assert x == y == run.id

## Init run meta

`init_run_meta()` initializes the run meta directory. It requires a run,
an op ref, an op def, op config, and an op command.

    >>> init_run_meta(run, OpDef("test", {}), {}, OpCmd([], {}))

    >>> ls(run.meta_dir)  # +diff
    __schema__
    config.json
    id
    initialized
    log/runner
    opdef.json
    opref
    proc/cmd.json
    proc/env.json

    >>> cat(run_meta_path(run, "opdef.json"))
    {}

## Copy source code

Source code copy is performed at two levels:

- Copy files matching `sourcecode` path patterns
- Run `stage-sourcecode` exec if specified

Create a sample project. The project has a `setup.py` script that is
used to initialize `config.json`.

    >>> project_dir = make_temp_dir()
    >>> cd(project_dir)

Sample train script (empty):

    >>> touch("train.py")

`setup.py` that generates config from a template. This script is run for
the copy source code phase.

    >>> write("config.json.in", "{\"x\": 123}")
    >>> write("setup.py", """
    ... import os, json
    ... run_dir = os.environ["run_dir"]
    ... print("Creating config.json from config.json.in")
    ... config = json.load(open("config.json.in"))
    ... config["x"] = config["x"] + 1
    ... print(f"Using x = {config['x']} for config")
    ... with open(os.path.join(run_dir, "config.json"), "w") as f:
    ...     json.dump(config, f)
    ... """)

Initialize a run with an opdef def that copies specifies the source code
to copy and also runs `setup.py` to generate `config.json` in the run
directory.

    >>> opdef = OpDef("test", {
    ...     "sourcecode": ["train.py", "setup.py", "config.json.in"],
    ...     "exec": {
    ...         "stage-sourcecode": ["python", "setup.py"]
    ...     }
    ... })

    >>> runs_home = make_temp_dir()

    >>> run = make_run(OpRef("test", "test"), runs_home)

    >>> init_run_meta(run, opdef, {}, OpCmd([], {}))

Use `stage_sourcecode()` to copy the source code and run the source code
exec.

    >>> stage_sourcecode(run, project_dir)

List the run files.

    >>> ls(run.run_dir)
    config.json
    config.json.in
    setup.py
    train.py

`setup.py` generates config derived from `config.json.in`.

    >>> cat(path_join(run.run_dir, "config.json"))
    {"x": 124}

The output file `10_sourcecode` is written to meta.

    >>> ls(run.meta_dir)  # +diff
    __schema__
    config.json
    id
    initialized
    log/files
    log/runner
    opdef.json
    opref
    output/10_sourcecode
    output/10_sourcecode.index
    proc/cmd.json
    proc/env.json

This contains the output generated by `setup.py`.

    >>> cat(run_meta_path(run, "output", "10_sourcecode"))
    Creating config.json from config.json.in
    Using x = 124 for config

`stage-sourcecode` phase events are written to the runner log.

    >>> cat_log(run_meta_path(run, "log", "runner"))  # +diff -space
    Writing meta id
    Writing meta opdef
    Writing meta config
    Writing meta proc cmd
    Writing meta proc env
    Writing meta initialized
    Copying source code (see log/files for details):
      ['train.py', 'setup.py', 'config.json.in']
    Running stage-sourcecode (see output/10_sourcecode for output):
      ['python', 'setup.py']
    Exit code for stage-sourcecode: 0

The list of source code files in `log/files` reflects the creation of
`config.json` by the copy sourcecode exec command.

    >>> cat(run_meta_path(run, "log", "files"))  # +parse
    a s {:timestamp} config.json.in
    a s {:timestamp} setup.py
    a s {:timestamp} config.json
    a s {:timestamp} train.py

`config.json` appears in the run manifest when meta staging is finalized.

    >>> finalize_staged_run(run)

    >>> cat(run_meta_path(run, "manifest"))
    s 2e800a0aca54fbeca8d7f5a75f6be7bde6bc12ce6d3c5fc0236edb69660b9ffd config.json.in
    s d49cee364b51492d3330dfa0ff98173704ac632e03a938e73036459fd56a9827 setup.py
    s 5cc1441b4902cd35921288754e412e0eb949d44d81e4e0fcb281a913a7c3e820 config.json
    s e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 train.py

## Copy dependencies

Like source code, dependencies are resolved at two levels:

- Copy files matching `requires` path patterns
- Run `stage-dependencies` exec if specified

`requires` support is pending. We show how `stage-dependencies` is used to copy
dependencies from a project directory to a run directory.

Create a project structure.

    >>> project_dir = make_temp_dir()
    >>> cd(project_dir)

Create a sample train script (empty).

    >>> touch("train.py")

Create a script that generates a required file `data.json`.

    >>> write("setup.py", """
    ... import sys, json
    ... x = int(sys.argv[1])
    ... print(f"Creating data.json with x = {x}")
    ... json.dump({"x": x}, open("data.json", "w"))
    ... """)

Create a new run.

    >>> run = make_run(OpRef("test", "test"), runs_root)

The op def specifies `train.py` as source code and uses `stage-dependencies` to
run `setup.py` to generate `data.json`.

    >>> opdef = OpDef("test", {
    ...     "sourcecode": "*.py",
    ...     "exec": {
    ...         "stage-dependencies": ["python", "setup.py", "456"]
    ...     }
    ... })

    >>> init_run_meta(run, opdef, {}, OpCmd([], {}))

The `stage-dependencies` hook requires `setup.py` - use
`stage_sourcecode()` to provide the required files.

    >>> stage_sourcecode(run, project_dir)

    >>> ls(run.run_dir)
    setup.py
    train.py

Use `stage_dependencies()` to run the copy dependencies exec command.

    >>> stage_dependencies(run, project_dir)

The runner log shows copy dependencies info.

    >>> cat_log(run_meta_path(run, "log", "runner"))  # +wildcard
    Writing meta id
    ...
    Running stage-dependencies (see output/30_dependencies for output): ['python', 'setup.py', '456']
    Exit code for stage-dependencies: 0

Output for the copy command is in `output/30_dependencies`.

    >>> ls(run.meta_dir)  # +wildcard
    __schema__
    ...
    output/30_dependencies
    output/30_dependencies.index
    ...

    >>> cat(run_meta_path(run, "output", "30_dependencies"))
    Creating data.json with x = 456

Files logged:

    >>> cat(run_meta_path(run, "log", "files"))  # +parse
    a s {:timestamp} setup.py
    a s {:timestamp} train.py
    a d {:timestamp} data.json

The 'd' in the record means the file is logged as a dependency.

List the run files.

    >>> ls(run.run_dir)
    data.json
    setup.py
    train.py

## Run attributes

Run attributes may be read from the run directly or from files written
to run meta. Use `run_attr()` to read either.

Attributes supported `run_attr()` are listed in the private module
variable `_ATTR_READERS`.

    >>> from gage._internal.run_util import _ATTR_READERS

    >>> sorted(_ATTR_READERS)  # +pprint
    ['dir', 'id', 'label', 'name', 'started', 'stopped']

Create a run that's not bound to a directory.

    >>> run = Run(
    ...     id="abc",
    ...     opref=OpRef("test", "test"),
    ...     meta_dir="/meta_dir",
    ...     run_dir="/run_dir",
    ...     name="def")

`run_attr()` provides access to a limited number of run attributes.
These are considered publicly accessible attributes. In one case, `dir`,
which maps to `run_dir`, the attribute is renamed.

    >>> run_attr(run, "id")
    'abc'

    >>> run_attr(run, "name")
    'def'

    >>> run_attr(run, "dir")
    '/run_dir'

Other attributes are read from disk. In this case, `run_attr()` raises
an attribute error unless a default is provided.

    >>> run_attr(run, "label")
    Traceback (most recent call last):
    AttributeError: label

    >>> run_attr(run, "label", "a default")
    'a default'

Create a run from a run meta directory.

    >>> meta_dir = make_temp_dir()

    >>> run = Run(
    ...     id="abc",
    ...     opref=OpRef("test", "test"),
    ...     meta_dir=meta_dir,
    ...     run_dir="/run_dir",
    ...     name="def")

    >>> init_run_meta(
    ...     run=run,
    ...     opdef=OpDef("test", {}),
    ...     config={},
    ...     cmd=OpCmd([], {}),
    ...     user_attrs={
    ...         "label": "Hello run",
    ...         "custom-123": 123
    ...     },
    ...     system_attrs={
    ...         "platform": "some-tests",
    ...         "custom-list": [1, 2, "shoe"]
    ...     }
    ... )

Core attributes:

    >>> run_attr(run, "id")
    'abc'

    >>> run_attr(run, "name")
    'def'

    >>> run_attr(run, "dir")
    '/run_dir'

User attribute `label` is available.

    >>> run_attr(run, "label")
    'Hello run'

Started and stopped timestamps are read from the meta dir. Neither are
present and attempting to read either generates an attribute error.

    >>> run_attr(run, "started")
    Traceback (most recent call last):
    AttributeError: started

    >>> run_attr(run, "stopped")
    Traceback (most recent call last):
    AttributeError: stopped

`read_attr()` returns specified defaults.

    >>> run_attr(run, "started", 123)
    123

    >>> run_attr(run, "stopped", 456)
    456

Write timestamps for started and stopped.

    >>> write(
    ...     run_meta_path(run, "started"),
    ...     str(make_run_timestamp())
    ... )

    >>> write(
    ...     run_meta_path(run, "stopped"),
    ...     str(make_run_timestamp())
    ... )

Re-read the attributes.

    >>> run_attr(run, "started")  # +wildcard
    datetime.datetime(...)

    >>> run_attr(run, "stopped")  # +wildcard
    datetime.datetime(...)

Reading an unsupported attribute generates an attribute error even if a
default is provided.

    >>> run_attr(run, "unknown")
    Traceback (most recent call last):
    AttributeError: unknown

    >>> run_attr(run, "unknown", 789)
    Traceback (most recent call last):
    AttributeError: unknown

When successfully read, attribute values are cached to avoid re-reading.

Re-write the run label.

    >>> write(
    ...     run_meta_path(run, "user", "label.json"),
    ...     "\"Modified label\"",
    ...     force=True
    ... )

Re-reading does not change the run attribute value.

    >>> run_attr(run, "label")
    'Hello run'

To force a re-read, recreate the run.

    >>> run = Run(
    ...     id="abc",
    ...     opref=OpRef("test", "test"),
    ...     meta_dir=meta_dir,
    ...     run_dir="/run_dir",
    ...     name="def")

    >>> run_attr(run, "label")
    'Modified label'

In cases where recreating a run is not desireable, the cache can be
invalidated directly by accessing `run._cache`.

    >>> run._cache  # +pprint
    {'_attr_label': 'Modified label'}

Re-write the label.

    >>> write(
    ...     run_meta_path(run, "user", "label.json"),
    ...     "\"Again modified\""
    ... )

The cached value is used.

    >>> run_attr(run, "label")
    'Modified label'

Invalidate the cache and read the label again.

    >>> run._cache.clear()

    >>> run_attr(run, "label")
    'Again modified'
